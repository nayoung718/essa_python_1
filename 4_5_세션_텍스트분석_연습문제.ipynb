{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nayoung718/essa_python_1/blob/main/4_5_%EC%84%B8%EC%85%98_%ED%85%8D%EC%8A%A4%ED%8A%B8%EB%B6%84%EC%84%9D_%EC%97%B0%EC%8A%B5%EB%AC%B8%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 아래의 데이터를 이용하여 공부한 내용을 바탕으로 문제 2개를 만들고 답하세요."
      ],
      "metadata": {
        "id": "MbDTRcUQrUS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"book\", quiet=True)\n",
        "from nltk.book import *"
      ],
      "metadata": {
        "id": "PNjdc83Bqdpd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ee54e3a-ef97-4467-ba2d-1a5f182f3a57"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Introductory Examples for the NLTK Book ***\n",
            "Loading text1, ..., text9 and sent1, ..., sent9\n",
            "Type the name of the text or sentence to view it.\n",
            "Type: 'texts()' or 'sents()' to list the materials.\n",
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 목록 확인\n",
        "nltk.corpus.gutenberg.fileids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9xoXfKzrbKv",
        "outputId": "fa798851-2fe5-4b3e-99dc-b71a71d73146"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emma = nltk.corpus.gutenberg.raw('austen-emma.txt')\n",
        "print(emma[:5000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo9kzrrqqaNc",
        "outputId": "c50006cb-433f-4127-dddb-c04b160c67b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Emma by Jane Austen 1816]\n",
            "\n",
            "VOLUME I\n",
            "\n",
            "CHAPTER I\n",
            "\n",
            "\n",
            "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
            "and happy disposition, seemed to unite some of the best blessings\n",
            "of existence; and had lived nearly twenty-one years in the world\n",
            "with very little to distress or vex her.\n",
            "\n",
            "She was the youngest of the two daughters of a most affectionate,\n",
            "indulgent father; and had, in consequence of her sister's marriage,\n",
            "been mistress of his house from a very early period.  Her mother\n",
            "had died too long ago for her to have more than an indistinct\n",
            "remembrance of her caresses; and her place had been supplied\n",
            "by an excellent woman as governess, who had fallen little short\n",
            "of a mother in affection.\n",
            "\n",
            "Sixteen years had Miss Taylor been in Mr. Woodhouse's family,\n",
            "less as a governess than a friend, very fond of both daughters,\n",
            "but particularly of Emma.  Between _them_ it was more the intimacy\n",
            "of sisters.  Even before Miss Taylor had ceased to hold the nominal\n",
            "office of governess, the mildness of her temper had hardly allowed\n",
            "her to impose any restraint; and the shadow of authority being\n",
            "now long passed away, they had been living together as friend and\n",
            "friend very mutually attached, and Emma doing just what she liked;\n",
            "highly esteeming Miss Taylor's judgment, but directed chiefly by\n",
            "her own.\n",
            "\n",
            "The real evils, indeed, of Emma's situation were the power of having\n",
            "rather too much her own way, and a disposition to think a little\n",
            "too well of herself; these were the disadvantages which threatened\n",
            "alloy to her many enjoyments.  The danger, however, was at present\n",
            "so unperceived, that they did not by any means rank as misfortunes\n",
            "with her.\n",
            "\n",
            "Sorrow came--a gentle sorrow--but not at all in the shape of any\n",
            "disagreeable consciousness.--Miss Taylor married.  It was Miss\n",
            "Taylor's loss which first brought grief.  It was on the wedding-day\n",
            "of this beloved friend that Emma first sat in mournful thought\n",
            "of any continuance.  The wedding over, and the bride-people gone,\n",
            "her father and herself were left to dine together, with no prospect\n",
            "of a third to cheer a long evening.  Her father composed himself\n",
            "to sleep after dinner, as usual, and she had then only to sit\n",
            "and think of what she had lost.\n",
            "\n",
            "The event had every promise of happiness for her friend.  Mr. Weston\n",
            "was a man of unexceptionable character, easy fortune, suitable age,\n",
            "and pleasant manners; and there was some satisfaction in considering\n",
            "with what self-denying, generous friendship she had always wished\n",
            "and promoted the match; but it was a black morning's work for her.\n",
            "The want of Miss Taylor would be felt every hour of every day.\n",
            "She recalled her past kindness--the kindness, the affection of sixteen\n",
            "years--how she had taught and how she had played with her from five\n",
            "years old--how she had devoted all her powers to attach and amuse\n",
            "her in health--and how nursed her through the various illnesses\n",
            "of childhood.  A large debt of gratitude was owing here; but the\n",
            "intercourse of the last seven years, the equal footing and perfect\n",
            "unreserve which had soon followed Isabella's marriage, on their\n",
            "being left to each other, was yet a dearer, tenderer recollection.\n",
            "She had been a friend and companion such as few possessed: intelligent,\n",
            "well-informed, useful, gentle, knowing all the ways of the family,\n",
            "interested in all its concerns, and peculiarly interested in herself,\n",
            "in every pleasure, every scheme of hers--one to whom she could speak\n",
            "every thought as it arose, and who had such an affection for her\n",
            "as could never find fault.\n",
            "\n",
            "How was she to bear the change?--It was true that her friend was\n",
            "going only half a mile from them; but Emma was aware that great must\n",
            "be the difference between a Mrs. Weston, only half a mile from them,\n",
            "and a Miss Taylor in the house; and with all her advantages,\n",
            "natural and domestic, she was now in great danger of suffering\n",
            "from intellectual solitude.  She dearly loved her father, but he\n",
            "was no companion for her.  He could not meet her in conversation,\n",
            "rational or playful.\n",
            "\n",
            "The evil of the actual disparity in their ages (and Mr. Woodhouse had\n",
            "not married early) was much increased by his constitution and habits;\n",
            "for having been a valetudinarian all his life, without activity\n",
            "of mind or body, he was a much older man in ways than in years;\n",
            "and though everywhere beloved for the friendliness of his heart\n",
            "and his amiable temper, his talents could not have recommended him\n",
            "at any time.\n",
            "\n",
            "Her sister, though comparatively but little removed by matrimony,\n",
            "being settled in London, only sixteen miles off, was much beyond\n",
            "her daily reach; and many a long October and November evening must\n",
            "be struggled through at Hartfield, before Christmas brought the next\n",
            "visit from Isabella and her husband, and their little children,\n",
            "to fill the house, and give her pleasant society again.\n",
            "\n",
            "Highbury, the large and populous village, almost amounting to a town,\n",
            "to which Hartfield, in spite of its separate lawn, and shrubberies,\n",
            "and name, did really belong, afforded her no equals.  The Woodhouses\n",
            "were \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (1) 문제 1 : CountVectorizer를 이용해 BOW 피처 벡터화하여 문장별 단어 개수를 많은 순으로 출력하고 단어별 총 출현 횟수도 출력하시오."
      ],
      "metadata": {
        "id": "iNftR22-riz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize"
      ],
      "metadata": {
        "id": "OPLMW3-Hqp5_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emma = nltk.corpus.gutenberg.raw('austen-emma.txt')\n",
        "\n",
        "# 텍스트를 문장으로 분할\n",
        "sentences = sent_tokenize(emma)\n",
        "\n",
        "# 문장별로 토큰화하여 리스트로 저장\n",
        "tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
        "\n",
        "# CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# 문장 리스트를 BOW 표현으로 변환\n",
        "bow_representation = vectorizer.fit_transform([' '.join(sentence) for sentence in tokenized_sentences])\n",
        "\n",
        "# 특성 이름을 가져옴 (어휘 사전에 있는 단어들)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# BOW 표현을 배열로 변환\n",
        "bow_array = bow_representation.toarray()\n",
        "\n",
        "# 특성 이름과 BOW 배열을 출력\n",
        "print(\"특성 이름:\", feature_names)\n",
        "print(\"BOW 배열:\", bow_array)"
      ],
      "metadata": {
        "id": "mLLGn_Rxrkxk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebfe18ea-6cd6-4e46-d98d-49242516cd93"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "특성 이름: ['000' '10' '1816' ... 'youthful' 'zeal' 'zigzags']\n",
            "BOW 배열: [[0 0 1 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CountVectorizer의 vocabulary를 이용하여 정렬된 형태의 DataFrame\n",
        "countvect_df = pd.DataFrame(bow_array, columns=sorted(vectorizer.vocabulary_.keys()))\n",
        "\n",
        "# 열 기준으로 합계를 구하여 많이 나온 순으로 정렬\n",
        "countvect_df_sum = countvect_df.sum(axis=0)\n",
        "\n",
        "# 많이 나온 순으로 정렬된 DataFrame을 출력\n",
        "sorted_countvect_df = countvect_df[countvect_df_sum.sort_values(ascending=False).index]\n",
        "print(sorted_countvect_df)\n",
        "\n",
        "print(\"-------------\")\n",
        "\n",
        "# 단어별로 총 출현 횟수를 출력\n",
        "total_word_counts = countvect_df_sum.sort_values(ascending=False)\n",
        "print(\"단어별 총 출현 횟수:\")\n",
        "print(total_word_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU6U1yeerxnn",
        "outputId": "1feabdbb-8b19-4472-f02e-718375cbadf8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      to  the  and  of  it  her  was  she  not  in  ...  impediment  impelled  \\\n",
            "0      2    2    3   2   0    1    0    0    0   1  ...           0         0   \n",
            "1      0    2    1   4   0    1    1    1    0   1  ...           0         0   \n",
            "2      1    0    1   2   0    4    0    0    0   1  ...           0         0   \n",
            "3      0    0    0   2   0    0    0    0    0   1  ...           0         0   \n",
            "4      0    1    0   1   1    0    1    0    0   0  ...           0         0   \n",
            "...   ..  ...  ...  ..  ..  ...  ...  ...  ...  ..  ...         ...       ...   \n",
            "7488   0    2    1   2   0    0    1    0    0   2  ...           0         0   \n",
            "7489   3    4    3   3   0    1    3    1    0   0  ...           0         0   \n",
            "7490   1    3    2   1   2    2    1    1    0   0  ...           0         0   \n",
            "7491   0    8    0   4   0    0    0    0    0   2  ...           0         0   \n",
            "7492   0    0    0   0   0    0    0    0    0   0  ...           0         0   \n",
            "\n",
            "      impending  impertinence  impertinently  implanted  implicitly  implore  \\\n",
            "0             0             0              0          0           0        0   \n",
            "1             0             0              0          0           0        0   \n",
            "2             0             0              0          0           0        0   \n",
            "3             0             0              0          0           0        0   \n",
            "4             0             0              0          0           0        0   \n",
            "...         ...           ...            ...        ...         ...      ...   \n",
            "7488          0             0              0          0           0        0   \n",
            "7489          0             0              0          0           0        0   \n",
            "7490          0             0              0          0           0        0   \n",
            "7491          0             0              0          0           0        0   \n",
            "7492          0             0              0          0           0        0   \n",
            "\n",
            "      impolite  zigzags  \n",
            "0            0        0  \n",
            "1            0        0  \n",
            "2            0        0  \n",
            "3            0        0  \n",
            "4            0        0  \n",
            "...        ...      ...  \n",
            "7488         0        0  \n",
            "7489         0        0  \n",
            "7490         0        0  \n",
            "7491         0        0  \n",
            "7492         0        0  \n",
            "\n",
            "[7493 rows x 7237 columns]\n",
            "-------------\n",
            "단어별 총 출현 횟수:\n",
            "to            5239\n",
            "the           5201\n",
            "and           4896\n",
            "of            4291\n",
            "it            2528\n",
            "              ... \n",
            "implanted        1\n",
            "implicitly       1\n",
            "implore          1\n",
            "impolite         1\n",
            "zigzags          1\n",
            "Length: 7237, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2) 문제 2 : TfidfVectorizer를 이용해 BOW 피처 벡터화하여 문장별 단어 개수를 많은 순으로 출력하고 단어별 총 출현 횟수도 출력하시오."
      ],
      "metadata": {
        "id": "F6fES2kkrmP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "emma = nltk.corpus.gutenberg.raw('austen-emma.txt')\n",
        "\n",
        "# 텍스트를 문장으로 분할\n",
        "sentences = sent_tokenize(emma)\n",
        "\n",
        "# 문장별로 토큰화하여 리스트로 저장\n",
        "tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
        "\n",
        "# TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# 문장 리스트를 TF-IDF 표현으로 변환\n",
        "tfidf_representation = vectorizer.fit_transform([' '.join(sentence) for sentence in tokenized_sentences])\n",
        "\n",
        "# 특성 이름을 가져옴 (어휘 사전에 있는 단어들)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "\n",
        "# TF-IDF 표현을 배열로 변환\n",
        "tfidf_array = tfidf_representation.toarray()\n",
        "\n",
        "# TF-IDF 배열을 출력\n",
        "print(\"TF-IDF 배열:\", tfidf_array)"
      ],
      "metadata": {
        "id": "a9vmAhP1rnIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b482adb8-c2c0-403e-abf8-85a5b6c09041"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF 배열: [[0.         0.         0.24286186 ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# TfidfVectorizer의 vocabulary를 이용하여 정렬된 형태의 DataFrame\n",
        "tfidf_df = pd.DataFrame(tfidf_array, columns=sorted(vectorizer.vocabulary_.keys()))\n",
        "\n",
        "# 열 기준으로 합계를 구하여 TF-IDF 값이 높은 순으로 정렬\n",
        "tfidf_df_sum = tfidf_df.sum(axis=0)\n",
        "\n",
        "# TF-IDF 값이 높은 순으로 정렬된 DataFrame을 출력\n",
        "sorted_tfidf_df = tfidf_df[tfidf_df_sum.sort_values(ascending=False).index]\n",
        "print(sorted_tfidf_df)\n",
        "\n",
        "# 단어별로 TF-IDF 값의 총합을 출력\n",
        "total_tfidf_values = tfidf_df_sum.sort_values(ascending=False)\n",
        "print(\"단어별 총 TF-IDF 값:\")\n",
        "print(total_tfidf_values)"
      ],
      "metadata": {
        "id": "c3PlmC3lrneg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a11f8598-73aa-48d6-bcb4-05fdbc642d1d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            to       the       and        of  you        it  not       she  \\\n",
            "0     0.098853  0.103905  0.154941  0.107424  0.0  0.000000  0.0  0.000000   \n",
            "1     0.000000  0.140185  0.069681  0.289868  0.0  0.000000  0.0  0.090887   \n",
            "2     0.053079  0.000000  0.055464  0.115363  0.0  0.000000  0.0  0.000000   \n",
            "3     0.000000  0.000000  0.000000  0.169606  0.0  0.000000  0.0  0.000000   \n",
            "4     0.000000  0.128479  0.000000  0.132831  0.0  0.152594  0.0  0.000000   \n",
            "...        ...       ...       ...       ...  ...       ...  ...       ...   \n",
            "7488  0.000000  0.155989  0.077536  0.161273  0.0  0.000000  0.0  0.000000   \n",
            "7489  0.146419  0.205202  0.152998  0.159115  0.0  0.000000  0.0  0.066520   \n",
            "7490  0.043640  0.137610  0.091201  0.047424  0.0  0.108960  0.0  0.059478   \n",
            "7491  0.000000  0.432579  0.000000  0.223616  0.0  0.000000  0.0  0.000000   \n",
            "7492  0.000000  0.000000  0.000000  0.000000  0.0  0.000000  0.0  0.000000   \n",
            "\n",
            "           was       her  ...  hautboy  sorts  hautboys  cultivation  \\\n",
            "0     0.000000  0.067365  ...      0.0    0.0       0.0          0.0   \n",
            "1     0.087126  0.090887  ...      0.0    0.0       0.0          0.0   \n",
            "2     0.000000  0.289372  ...      0.0    0.0       0.0          0.0   \n",
            "3     0.000000  0.000000  ...      0.0    0.0       0.0          0.0   \n",
            "4     0.159700  0.000000  ...      0.0    0.0       0.0          0.0   \n",
            "...        ...       ...  ...      ...    ...       ...          ...   \n",
            "7488  0.096948  0.000000  ...      0.0    0.0       0.0          0.0   \n",
            "7489  0.191301  0.066520  ...      0.0    0.0       0.0          0.0   \n",
            "7490  0.057017  0.118956  ...      0.0    0.0       0.0          0.0   \n",
            "7491  0.000000  0.000000  ...      0.0    0.0       0.0          0.0   \n",
            "7492  0.000000  0.000000  ...      0.0    0.0       0.0          0.0   \n",
            "\n",
            "      apparatus  chili  currants  eatable  flavour  cherries  \n",
            "0           0.0    0.0       0.0      0.0      0.0       0.0  \n",
            "1           0.0    0.0       0.0      0.0      0.0       0.0  \n",
            "2           0.0    0.0       0.0      0.0      0.0       0.0  \n",
            "3           0.0    0.0       0.0      0.0      0.0       0.0  \n",
            "4           0.0    0.0       0.0      0.0      0.0       0.0  \n",
            "...         ...    ...       ...      ...      ...       ...  \n",
            "7488        0.0    0.0       0.0      0.0      0.0       0.0  \n",
            "7489        0.0    0.0       0.0      0.0      0.0       0.0  \n",
            "7490        0.0    0.0       0.0      0.0      0.0       0.0  \n",
            "7491        0.0    0.0       0.0      0.0      0.0       0.0  \n",
            "7492        0.0    0.0       0.0      0.0      0.0       0.0  \n",
            "\n",
            "[7493 rows x 7237 columns]\n",
            "단어별 총 TF-IDF 값:\n",
            "to          372.705787\n",
            "the         368.260676\n",
            "and         330.702952\n",
            "of          314.837178\n",
            "you         278.366365\n",
            "               ...    \n",
            "chili         0.085638\n",
            "currants      0.085638\n",
            "eatable       0.085638\n",
            "flavour       0.085638\n",
            "cherries      0.085638\n",
            "Length: 7237, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그 둘의 차이점은?\n",
        "\n",
        "CountVectorizer는 각 단어의 출현 빈도를 사용하여 문서를 표현, TfidfVectorizer는 단어의 출현 빈도 뿐만 아니라 해당 단어가 다른 문서에 출현하는 빈도에 대한 정보도 고려하여 단어의 중요도를 계산"
      ],
      "metadata": {
        "id": "2hEorBf3q3gW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 조원들과 만든 문제와 답을 공유해보세요."
      ],
      "metadata": {
        "id": "2EvgMg6VsMz0"
      }
    }
  ]
}